{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import awscli\n",
    "import sys\n",
    "import selenium\n",
    "import unittest\n",
    "import boto3\n",
    "import pandas as pd\n",
    "import tabulate\n",
    "import time\n",
    "import requests\n",
    "import csv\n",
    "import socket \n",
    "import numpy as np\n",
    "import dataframe\n",
    "from bs4 import BeautifulSoup\n",
    "from tabulate import tabulate\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# For 1st part (~236)\n",
    "browser = webdriver.Chrome(r\"C:\\Users\\...\\chromedriver.exe\")\n",
    "browser.get('https://fortune.com/global500/2018/walmart')\n",
    "\n",
    "df1 = pd.DataFrame(columns=['Revenues_$M','Profits_$M', 'Assets_$M', 'Total_Stockholder_Equity_$M','Profit_as_%_of_Revenues', 'Profits_as_%_of_Assets', 'Profits_as_%_of_Stockholder_Equity'])\n",
    "c1 = []\n",
    "\n",
    "for i in [x for x in range(236)]:       \n",
    "    table = browser.find_element_by_xpath('//*[@id=\"content\"]/div[5]/div[1]/table/tbody')    \n",
    "    if i > 236:\n",
    "        break\n",
    "\n",
    "\n",
    "    try:\n",
    "        print(\"Scraping Page no. \" + str(i))\n",
    "        i = i + 1\n",
    "    \n",
    "        for row in table.find_elements_by_css_selector('tr.dataTable__row--34F3j'):\n",
    "            vals=[]\n",
    "            vals.append(str(([cell.text for cell in row.find_elements_by_xpath('//*[@id=\"content\"]/div[5]/div[1]/table/tbody/tr[1]/td[2]')])).strip('[]').strip(\"''\"))   \n",
    "            vals.append(str(([cell.text for cell in row.find_elements_by_xpath('//*[@id=\"content\"]/div[5]/div[1]/table/tbody/tr[2]/td[2]')])).strip('[]').strip(\"''\"))   \n",
    "            vals.append(str(([cell.text for cell in row.find_elements_by_xpath('//*[@id=\"content\"]/div[5]/div[1]/table/tbody/tr[3]/td[2]')])).strip('[]').strip(\"''\"))   \n",
    "            vals.append(str(([cell.text for cell in row.find_elements_by_xpath('//*[@id=\"content\"]/div[5]/div[1]/table/tbody/tr[4]/td[2]')])).strip('[]').strip(\"''\"))   \n",
    "            vals.append(str(([cell.text for cell in row.find_elements_by_xpath('//*[@id=\"content\"]/div[5]/div[2]/table/tbody/tr[1]/td[2]')])).strip('[]').strip(\"''\"))\n",
    "            vals.append(str(([cell.text for cell in row.find_elements_by_xpath('//*[@id=\"content\"]/div[5]/div[2]/table/tbody/tr[2]/td[2]')])).strip('[]').strip(\"''\"))\n",
    "            vals.append(str(([cell.text for cell in row.find_elements_by_xpath('//*[@id=\"content\"]/div[5]/div[2]/table/tbody/tr[3]/td[2]')])).strip('[]').strip(\"''\"))            \n",
    "\n",
    "        comp1 = str(([c.text for c in row.find_elements_by_xpath('//*[@id=\"content\"]/div[1]/div[1]/div/h1/span')])).strip('[]').strip(\"''\")    \n",
    "                                                                           \n",
    "        c1.append(comp1)\n",
    "        \n",
    "        s1 = pd.Series(vals,index=df1.columns)\n",
    "\n",
    "        cs1 = pd.Series(c1) \n",
    "        df1 = df1.append(s1,ignore_index=True)\n",
    "        \n",
    "        try:\n",
    "\n",
    "            WebDriverWait(browser, 6).until(EC.element_to_be_clickable((By.CSS_SELECTOR, \"div.singlePagination__next2--3D89W\"))).click()\n",
    "            time.sleep(5)\n",
    "\n",
    "        except (socket.gaierror, requests.ConnectionError) as e:\n",
    "            if e.errno != 10054:\n",
    "                continue\n",
    "            reconnect()\n",
    "\n",
    "\n",
    "\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        break\n",
    "\n",
    "df1['company'] = cs1\n",
    "\n",
    "df1['year'] = 2018\n",
    "\n",
    "re_index = pd.Series(range(1,237))  \n",
    "df1 = df1.set_index([re_index])    \n",
    "\n",
    "\n",
    "\n",
    "print(df1)\n",
    "\n",
    "browser.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.to_csv(r'C:\\Users\\...\\key_financials_and_profit_ratio_2018_p1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# For 2nd part (237~500)\n",
    "browser = webdriver.Chrome(r\"C:\\Users\\...\\chromedriver.exe\")\n",
    "browser.get('https://fortune.com/global500/2018/industrial-bank')\n",
    "\n",
    "df2 = pd.DataFrame(columns=['Revenues_$M','Profits_$M', 'Assets_$M', 'Total_Stockholder_Equity_$M','Profit_as_%_of_Revenues', 'Profits_as_%_of_Assets', 'Profits_as_%_of_Stockholder_Equity'])\n",
    "c2 = []\n",
    "\n",
    "for i in [x for x in range(264)]:       \n",
    "    table = browser.find_element_by_xpath('//*[@id=\"content\"]/div[5]/div[1]/table/tbody')    \n",
    "    if i > 264:\n",
    "        break\n",
    "\n",
    "\n",
    "    try:\n",
    "        print(\"Scraping Page no. \" + str(i))\n",
    "        i = i + 1\n",
    "    \n",
    "        for row in table.find_elements_by_css_selector('tr.dataTable__row--34F3j'):\n",
    "            vals2=[]\n",
    "            vals2.append(str(([cell.text for cell in row.find_elements_by_xpath('//*[@id=\"content\"]/div[5]/div[1]/table/tbody/tr[1]/td[2]')])).strip('[]').strip(\"''\"))   \n",
    "            vals2.append(str(([cell.text for cell in row.find_elements_by_xpath('//*[@id=\"content\"]/div[5]/div[1]/table/tbody/tr[2]/td[2]')])).strip('[]').strip(\"''\"))   \n",
    "            vals2.append(str(([cell.text for cell in row.find_elements_by_xpath('//*[@id=\"content\"]/div[5]/div[1]/table/tbody/tr[3]/td[2]')])).strip('[]').strip(\"''\"))   \n",
    "            vals2.append(str(([cell.text for cell in row.find_elements_by_xpath('//*[@id=\"content\"]/div[5]/div[1]/table/tbody/tr[4]/td[2]')])).strip('[]').strip(\"''\"))   \n",
    "            vals2.append(str(([cell.text for cell in row.find_elements_by_xpath('//*[@id=\"content\"]/div[5]/div[2]/table/tbody/tr[1]/td[2]')])).strip('[]').strip(\"''\"))\n",
    "            vals2.append(str(([cell.text for cell in row.find_elements_by_xpath('//*[@id=\"content\"]/div[5]/div[2]/table/tbody/tr[2]/td[2]')])).strip('[]').strip(\"''\"))\n",
    "            vals2.append(str(([cell.text for cell in row.find_elements_by_xpath('//*[@id=\"content\"]/div[5]/div[2]/table/tbody/tr[3]/td[2]')])).strip('[]').strip(\"''\"))            \n",
    "\n",
    "        comp2 = str(([c.text for c in row.find_elements_by_xpath('//*[@id=\"content\"]/div[1]/div[1]/div/h1/span')])).strip('[]').strip(\"''\")    \n",
    "                                                                           \n",
    "        c2.append(comp2)\n",
    "        \n",
    "        s2 = pd.Series(vals2,index=df2.columns)\n",
    "\n",
    "        cs2 = pd.Series(c2) \n",
    "        df2 = df2.append(s2,ignore_index=True)\n",
    "        \n",
    "        try:\n",
    "\n",
    "            WebDriverWait(browser, 6).until(EC.element_to_be_clickable((By.CSS_SELECTOR, \"div.singlePagination__next2--3D89W\"))).click()\n",
    "            time.sleep(5)\n",
    "\n",
    "        except (socket.gaierror, requests.ConnectionError) as e:\n",
    "            if e.errno != 10054:\n",
    "                continue\n",
    "            reconnect()\n",
    "\n",
    "\n",
    "\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        break\n",
    "\n",
    "df2['company'] = cs2\n",
    "\n",
    "df2['year'] = 2018\n",
    "\n",
    "re_index1 = pd.Series(range(237,501))  \n",
    "df2 = df2.set_index([re_index1])    \n",
    "\n",
    "\n",
    "print(df2)\n",
    "\n",
    "browser.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
<<<<<<< HEAD
    "df2.to_csv(r'C:\\Users\\...\\Company_Valuation\\key_financials_and_profit_ratio_2018_p2.csv')"
=======
    "df2.to_csv(r'C:\\Users\\...\\key_financials_and_profit_ratio_2018_p2.csv')"
>>>>>>> 9e9c144e7d76544bf49b9e9674139e5ab58cf3a1
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reindex the dataframe\n",
    "\n",
    "company_key_financials_all=df1.append(df2, ignore_index=False)\n",
    "print(company_key_financials_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "company_key_financials_all.to_csv(r'C:\\Users\\...\\key_financials_and_profit_ratio_all_2018_v1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from botocore.client import Config\n",
    "from io import StringIO\n",
    "\n",
    "ACCESS_KEY_ID = 'your_access_key_id'\n",
    "ACCESS_SECRET_KEY = 'your_access_secret_key'\n",
    "BUCKET_NAME = 'ceo-culture-sagemaker'\n",
    "\n",
    "csv_buffer =StringIO()\n",
    "df1.to_csv(csv_buffer)\n",
    "\n",
    "s3 = boto3.resource(\n",
    "        's3',\n",
    "        aws_access_key_id = ACCESS_KEY_ID,\n",
    "        aws_secret_access_key=ACCESS_SECRET_KEY,\n",
    "        config=Config(signature_version='s3v4')\n",
    "        )\n",
    "s3.Bucket(BUCKET_NAME).put_object(Key='key_financials_and_profit_ratio_all_2018_v1.csv', Body = csv_buffer.getvalue())\n",
    "\n",
    "print(\"Uploaded\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
