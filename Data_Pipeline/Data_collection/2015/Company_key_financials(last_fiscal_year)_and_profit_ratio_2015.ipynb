{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import awscli\n",
    "import sys\n",
    "import selenium\n",
    "import unittest\n",
    "import boto3\n",
    "import pandas as pd\n",
    "import tabulate\n",
    "import time\n",
    "import requests\n",
    "import csv\n",
    "import socket \n",
    "import numpy as np\n",
    "import dataframe\n",
    "from bs4 import BeautifulSoup\n",
    "from tabulate import tabulate\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "browser = webdriver.Chrome(r\"C:\\Users\\...\\chromedriver.exe\")\n",
    "browser.get('https://fortune.com/global500/2015/walmart')\n",
    "\n",
    "df1 = pd.DataFrame(columns=['Revenues_$M','Profits_$M', 'Assets_$M', 'Employees', 'Profit_as_%_of_Revenues', 'Profits_as_%_of_Assets', 'Profits_as_%_of_Stockholder_Equity'])\n",
    "c1 = []\n",
    "\n",
    "for i in [x for x in range(500)]:       \n",
    "    table = browser.find_element_by_xpath('//*[@id=\"content\"]/div[5]/div[1]/table/tbody')    \n",
    "    if i > 500:\n",
    "        break\n",
    "\n",
    "\n",
    "    try:\n",
    "        print(\"Scraping Page no. \" + str(i))\n",
    "        i = i + 1\n",
    "    \n",
    "        for row in table.find_elements_by_css_selector('tr.dataTable__row--34F3j'):\n",
    "            vals=[]\n",
    "            vals.append(str(([cell.text for cell in row.find_elements_by_xpath('//*[@id=\"content\"]/div[5]/div[1]/table/tbody/tr[1]/td[2]')])).strip('[]').strip(\"''\"))   \n",
    "            vals.append(str(([cell.text for cell in row.find_elements_by_xpath('//*[@id=\"content\"]/div[5]/div[1]/table/tbody/tr[2]/td[2]')])).strip('[]').strip(\"''\"))   \n",
    "            vals.append(str(([cell.text for cell in row.find_elements_by_xpath('//*[@id=\"content\"]/div[5]/div[1]/table/tbody/tr[3]/td[2]')])).strip('[]').strip(\"''\"))   \n",
    "            vals.append(str(([cell.text for cell in row.find_elements_by_xpath('//*[@id=\"content\"]/div[5]/div[1]/table/tbody/tr[4]/td[2]')])).strip('[]').strip(\"''\"))   \n",
    "            vals.append(str(([cell.text for cell in row.find_elements_by_xpath('//*[@id=\"content\"]/div[5]/div[2]/table/tbody/tr[1]/td[2]')])).strip('[]').strip(\"''\"))\n",
    "            vals.append(str(([cell.text for cell in row.find_elements_by_xpath('//*[@id=\"content\"]/div[5]/div[2]/table/tbody/tr[2]/td[2]')])).strip('[]').strip(\"''\"))\n",
    "            vals.append(str(([cell.text for cell in row.find_elements_by_xpath('//*[@id=\"content\"]/div[5]/div[2]/table/tbody/tr[3]/td[2]')])).strip('[]').strip(\"''\"))            \n",
    "\n",
    "        comp1 = str(([c.text for c in row.find_elements_by_xpath('//*[@id=\"content\"]/div[1]/div[1]/div/h1/span')])).strip('[]').strip(\"''\")    \n",
    "                                                                           \n",
    "        c1.append(comp1)\n",
    "        \n",
    "        s1 = pd.Series(vals,index=df1.columns)\n",
    "\n",
    "        cs1 = pd.Series(c1) \n",
    "        df1 = df1.append(s1,ignore_index=True)\n",
    "        \n",
    "        try:\n",
    "\n",
    "            WebDriverWait(browser, 6).until(EC.element_to_be_clickable((By.CSS_SELECTOR, \"div.singlePagination__next2--3D89W\"))).click()\n",
    "            time.sleep(5)\n",
    "\n",
    "        except (socket.gaierror, requests.ConnectionError) as e:\n",
    "            if e.errno != 10054:\n",
    "                continue\n",
    "            reconnect()\n",
    "\n",
    "\n",
    "\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        break\n",
    "\n",
    "df1['company'] = cs1\n",
    "df1['year'] = 2015\n",
    "\n",
    "re_index = pd.Series(range(1,501))  \n",
    "df1 = df1.set_index([re_index])    \n",
    "\n",
    "print(df1)\n",
    "\n",
    "browser.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.to_csv(r'C:\\Users\\...\\key_financials_and_profit_ratio_all_2015_v1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from botocore.client import Config\n",
    "from io import StringIO\n",
    "\n",
    "ACCESS_KEY_ID = 'your_access_key_id'\n",
    "ACCESS_SECRET_KEY = 'your_access_secret_key'\n",
    "BUCKET_NAME = 'ceo-culture-sagemaker'\n",
    "\n",
    "csv_buffer =StringIO()\n",
    "df1.to_csv(csv_buffer)\n",
    "\n",
    "s3 = boto3.resource(\n",
    "        's3',\n",
    "        aws_access_key_id = ACCESS_KEY_ID,\n",
    "        aws_secret_access_key=ACCESS_SECRET_KEY,\n",
    "        config=Config(signature_version='s3v4')\n",
    "        )\n",
    "s3.Bucket(BUCKET_NAME).put_object(Key='key_financials_and_profit_ratio_all_2015_v1.csv', Body = csv_buffer.getvalue())\n",
    "\n",
    "print(\"Uploaded\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
