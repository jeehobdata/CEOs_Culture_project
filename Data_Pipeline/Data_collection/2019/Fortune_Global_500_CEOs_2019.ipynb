{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Web Scraping: Fortune Global 500 CEOs (2019)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import awscli\n",
    "import sys\n",
    "import selenium\n",
    "import unittest\n",
    "import boto3\n",
    "import pandas as pd\n",
    "import tabulate\n",
    "import time\n",
    "import requests\n",
    "import csv\n",
    "import socket \n",
    "import numpy as np\n",
    "import dataframe\n",
    "from bs4 import BeautifulSoup\n",
    "from tabulate import tabulate\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# For 1st part (~266)\n",
    "browser = webdriver.Chrome(r\"C:\\Users\\...\\chromedriver.exe\")\n",
    "browser.get('https://fortune.com/global500/2019/walmart')\n",
    "\n",
    "#For the  1st part\n",
    "\n",
    "df1 = pd.DataFrame(columns=['CEO','Sector', 'Industry', 'HQ Location', 'Website', 'Years on Global 500 List', 'Employees'])\n",
    "c1 = []\n",
    "\n",
    "for i in [x for x in range(266)]:         \n",
    "    table = browser.find_element_by_css_selector('tbody')\n",
    "    \n",
    "    if i > 266:\n",
    "        break\n",
    "\n",
    "\n",
    "    try:\n",
    "        print(\"Scraping Page no. \" + str(i))\n",
    "        i = i + 1\n",
    "        values1 =[]\n",
    "    \n",
    "        for row in table.find_elements_by_css_selector('tr'):\n",
    "            value1 = str(([cell.text for cell in row.find_elements_by_css_selector('td.dataTable__value--3n5tL.dataTable__valueAlignLeft--3uvNx')])).strip('[]').strip(\"''\")\n",
    "            values1.append(value1)\n",
    "            comp1 = str(([c.text for c in row.find_elements_by_xpath('//*[@id=\"content\"]/div[1]/div[1]/div/h1/span')])).strip('[]').strip(\"''\")    \n",
    "        c1.append(comp1)\n",
    "        \n",
    "        s1 = pd.Series(values1,index=df1.columns)\n",
    "        cs1 = pd.Series(c1) \n",
    "        df1 = df1.append(s1,ignore_index=True)\n",
    "        \n",
    "        try:\n",
    "\n",
    "            WebDriverWait(browser, 6).until(EC.element_to_be_clickable((By.CSS_SELECTOR, \"div.singlePagination__next2--3D89W\"))).click()\n",
    "            time.sleep(5)\n",
    "\n",
    "        except (socket.gaierror, requests.ConnectionError) as e:\n",
    "            if e.errno != 10054:\n",
    "                continue\n",
    "            reconnect()\n",
    "\n",
    "\n",
    "\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        break\n",
    "\n",
    "df1['company'] = cs1\n",
    "df1['year']=2019\n",
    "\n",
    "re_index = pd.Series(range(1,267))  \n",
    "df1 = df1.set_index([re_index])\n",
    "print(df1)\n",
    "\n",
    "browser.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.to_csv(r'C:\\Users\\...\\fg500_CEOs_2019_p1(Apr_25_2020).csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# For 2nd part (268~)\n",
    "browser = webdriver.Chrome(r\"C:\\Users\\...\\chromedriver.exe\")\n",
    "browser.get('https://fortune.com/global500/2019/new-york-life-insurance/')\n",
    "\n",
    "df2 = pd.DataFrame(columns=['CEO','Sector', 'Industry', 'HQ Location', 'Website', 'Years on Global 500 List', 'Employees'])\n",
    "c2 = []\n",
    "\n",
    "for i in [x for x in range(233)]:       \n",
    "    table = browser.find_element_by_css_selector('tbody')\n",
    "    \n",
    "    if i > 233:\n",
    "        break\n",
    "\n",
    "\n",
    "    try:\n",
    "        print(\"Scraping Page no. \" + str(i))\n",
    "        i = i + 1\n",
    "        values2 =[]\n",
    "    \n",
    "        for row in table.find_elements_by_css_selector('tr'):\n",
    "            value2 = str(([cell.text for cell in row.find_elements_by_css_selector('td.dataTable__value--3n5tL.dataTable__valueAlignLeft--3uvNx')])).strip('[]').strip(\"''\")\n",
    "            values2.append(value2)\n",
    "            comp2 = str(([c.text for c in row.find_elements_by_xpath('//*[@id=\"content\"]/div[1]/div[1]/div/h1/span')])).strip('[]').strip(\"''\")    \n",
    "        c2.append(comp2)\n",
    "        \n",
    "        s2 = pd.Series(values2,index=df2.columns)\n",
    "        cs2 = pd.Series(c2) \n",
    "        df2 = df2.append(s2,ignore_index=True)\n",
    "        \n",
    "        try:\n",
    "\n",
    "            WebDriverWait(browser, 6).until(EC.element_to_be_clickable((By.CSS_SELECTOR, \"div.singlePagination__next2--3D89W\"))).click()\n",
    "            time.sleep(5)\n",
    "\n",
    "        except (socket.gaierror, requests.ConnectionError) as e:\n",
    "            if e.errno != 10054:\n",
    "                continue\n",
    "            reconnect()\n",
    "\n",
    "\n",
    "\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        break\n",
    "\n",
    "df2['company'] = cs2\n",
    "df2['year']=2019\n",
    "\n",
    "re_index1 = pd.Series(range(268,501))  \n",
    "df2 = df2.set_index([re_index1])\n",
    "\n",
    "print(df2)\n",
    "\n",
    "browser.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.to_csv(r'C:\\Users\\...\\fg500_CEOs_2019_p2(Apr_25_2020).csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ceo_com=df1.append(df2, ignore_index=False)\n",
    "print(df_ceo_com)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ceo_com.to_csv(r'C:\\Users\\...\\fg500_CEOs_2019_All(Apr_25_2020).csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from botocore.client import Config\n",
    "from io import StringIO\n",
    "\n",
    "ACCESS_KEY_ID = 'your_access_key_id'\n",
    "ACCESS_SECRET_KEY = 'your_access_secret_key'\n",
    "BUCKET_NAME = 'ceo-culture-sagemaker'\n",
    "\n",
    "csv_buffer =StringIO()\n",
    "df1.to_csv(csv_buffer)\n",
    "\n",
    "s3 = boto3.resource(\n",
    "        's3',\n",
    "        aws_access_key_id = ACCESS_KEY_ID,\n",
    "        aws_secret_access_key=ACCESS_SECRET_KEY,\n",
    "        config=Config(signature_version='s3v4')\n",
    "        )\n",
    "s3.Bucket(BUCKET_NAME).put_object(Key='fg500_CEOs_2019_All(Apr_25_2020).csv', Body = csv_buffer.getvalue())\n",
    "\n",
    "print(\"Uploaded\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
