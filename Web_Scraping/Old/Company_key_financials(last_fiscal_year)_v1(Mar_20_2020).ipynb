{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import awscli\n",
    "import sys\n",
    "import selenium\n",
    "import unittest\n",
    "import boto3\n",
    "import pandas as pd\n",
    "import tabulate\n",
    "import time\n",
    "import requests\n",
    "import csv\n",
    "import socket \n",
    "import numpy as np\n",
    "import dataframe\n",
    "from bs4 import BeautifulSoup\n",
    "from tabulate import tabulate\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping Page no. 0\n",
      "Scraping Page no. 1\n",
      "Scraping Page no. 2\n",
      "Scraping Page no. 3\n",
      "Scraping Page no. 4\n",
      "Scraping Page no. 5\n",
      "Scraping Page no. 6\n",
      "Scraping Page no. 7\n",
      "Scraping Page no. 8\n",
      "Scraping Page no. 9\n",
      "Scraping Page no. 10\n",
      "Scraping Page no. 11\n",
      "Scraping Page no. 12\n",
      "Scraping Page no. 13\n",
      "Scraping Page no. 14\n",
      "Scraping Page no. 15\n",
      "Scraping Page no. 16\n",
      "Scraping Page no. 17\n",
      "Scraping Page no. 18\n",
      "Scraping Page no. 19\n",
      "Scraping Page no. 20\n",
      "Scraping Page no. 21\n",
      "Scraping Page no. 22\n",
      "Scraping Page no. 23\n",
      "Scraping Page no. 24\n",
      "Scraping Page no. 25\n",
      "Scraping Page no. 26\n",
      "Scraping Page no. 27\n",
      "Scraping Page no. 28\n",
      "Scraping Page no. 29\n",
      "Scraping Page no. 30\n",
      "Scraping Page no. 31\n",
      "Scraping Page no. 32\n",
      "Scraping Page no. 33\n",
      "Scraping Page no. 34\n",
      "Scraping Page no. 35\n",
      "Scraping Page no. 36\n",
      "Scraping Page no. 37\n",
      "Scraping Page no. 38\n",
      "Scraping Page no. 39\n",
      "Scraping Page no. 40\n",
      "Scraping Page no. 41\n",
      "Scraping Page no. 42\n",
      "Scraping Page no. 43\n",
      "Scraping Page no. 44\n",
      "Scraping Page no. 45\n",
      "Scraping Page no. 46\n",
      "Scraping Page no. 47\n",
      "Scraping Page no. 48\n",
      "Scraping Page no. 49\n",
      "Scraping Page no. 50\n",
      "Scraping Page no. 51\n",
      "Scraping Page no. 52\n",
      "Scraping Page no. 53\n",
      "Scraping Page no. 54\n",
      "Scraping Page no. 55\n",
      "Scraping Page no. 56\n",
      "Scraping Page no. 57\n",
      "Scraping Page no. 58\n",
      "Scraping Page no. 59\n",
      "Scraping Page no. 60\n",
      "Scraping Page no. 61\n",
      "Scraping Page no. 62\n",
      "Scraping Page no. 63\n",
      "Scraping Page no. 64\n",
      "Scraping Page no. 65\n",
      "Scraping Page no. 66\n",
      "Scraping Page no. 67\n",
      "Scraping Page no. 68\n",
      "Scraping Page no. 69\n",
      "Scraping Page no. 70\n",
      "Scraping Page no. 71\n",
      "Scraping Page no. 72\n",
      "Scraping Page no. 73\n",
      "Scraping Page no. 74\n",
      "Scraping Page no. 75\n",
      "Scraping Page no. 76\n",
      "Scraping Page no. 77\n",
      "Scraping Page no. 78\n",
      "Scraping Page no. 79\n",
      "Scraping Page no. 80\n",
      "Scraping Page no. 81\n",
      "Scraping Page no. 82\n",
      "Scraping Page no. 83\n",
      "Scraping Page no. 84\n",
      "Scraping Page no. 85\n",
      "Scraping Page no. 86\n",
      "Scraping Page no. 87\n",
      "Scraping Page no. 88\n",
      "Scraping Page no. 89\n",
      "Scraping Page no. 90\n",
      "Scraping Page no. 91\n",
      "Scraping Page no. 92\n",
      "Scraping Page no. 93\n",
      "Scraping Page no. 94\n",
      "Scraping Page no. 95\n",
      "Scraping Page no. 96\n",
      "Scraping Page no. 97\n",
      "Scraping Page no. 98\n",
      "Scraping Page no. 99\n",
      "Scraping Page no. 100\n",
      "Scraping Page no. 101\n",
      "Scraping Page no. 102\n",
      "Scraping Page no. 103\n",
      "Scraping Page no. 104\n",
      "Scraping Page no. 105\n",
      "Scraping Page no. 106\n",
      "Scraping Page no. 107\n",
      "Scraping Page no. 108\n",
      "Scraping Page no. 109\n",
      "Scraping Page no. 110\n",
      "Scraping Page no. 111\n",
      "Scraping Page no. 112\n",
      "Scraping Page no. 113\n",
      "Scraping Page no. 114\n",
      "Scraping Page no. 115\n",
      "Scraping Page no. 116\n",
      "Scraping Page no. 117\n",
      "Scraping Page no. 118\n",
      "Scraping Page no. 119\n",
      "Scraping Page no. 120\n",
      "Scraping Page no. 121\n",
      "Scraping Page no. 122\n",
      "Scraping Page no. 123\n",
      "Scraping Page no. 124\n",
      "Scraping Page no. 125\n",
      "Scraping Page no. 126\n",
      "Scraping Page no. 127\n",
      "Scraping Page no. 128\n",
      "Scraping Page no. 129\n",
      "Scraping Page no. 130\n",
      "Scraping Page no. 131\n",
      "Scraping Page no. 132\n",
      "Scraping Page no. 133\n",
      "Scraping Page no. 134\n",
      "Scraping Page no. 135\n",
      "Scraping Page no. 136\n",
      "Scraping Page no. 137\n",
      "Scraping Page no. 138\n",
      "Scraping Page no. 139\n",
      "Scraping Page no. 140\n",
      "Scraping Page no. 141\n",
      "Scraping Page no. 142\n",
      "Scraping Page no. 143\n",
      "Scraping Page no. 144\n",
      "Scraping Page no. 145\n",
      "Scraping Page no. 146\n",
      "Scraping Page no. 147\n",
      "Scraping Page no. 148\n",
      "Scraping Page no. 149\n",
      "Scraping Page no. 150\n",
      "Scraping Page no. 151\n",
      "Scraping Page no. 152\n",
      "Scraping Page no. 153\n",
      "Scraping Page no. 154\n",
      "Scraping Page no. 155\n",
      "Scraping Page no. 156\n",
      "Scraping Page no. 157\n",
      "Scraping Page no. 158\n",
      "Scraping Page no. 159\n",
      "Scraping Page no. 160\n",
      "Scraping Page no. 161\n",
      "Scraping Page no. 162\n",
      "Scraping Page no. 163\n",
      "Scraping Page no. 164\n",
      "Scraping Page no. 165\n",
      "Scraping Page no. 166\n",
      "Scraping Page no. 167\n",
      "Scraping Page no. 168\n",
      "Scraping Page no. 169\n",
      "Scraping Page no. 170\n",
      "Scraping Page no. 171\n",
      "Scraping Page no. 172\n",
      "Scraping Page no. 173\n",
      "Scraping Page no. 174\n",
      "Scraping Page no. 175\n",
      "Scraping Page no. 176\n",
      "Scraping Page no. 177\n",
      "Scraping Page no. 178\n",
      "Scraping Page no. 179\n",
      "Scraping Page no. 180\n",
      "Scraping Page no. 181\n",
      "Scraping Page no. 182\n",
      "Scraping Page no. 183\n",
      "Scraping Page no. 184\n",
      "Scraping Page no. 185\n",
      "Scraping Page no. 186\n",
      "Scraping Page no. 187\n",
      "Scraping Page no. 188\n",
      "Scraping Page no. 189\n",
      "Scraping Page no. 190\n",
      "Scraping Page no. 191\n",
      "Scraping Page no. 192\n",
      "Scraping Page no. 193\n",
      "Scraping Page no. 194\n",
      "Scraping Page no. 195\n",
      "Scraping Page no. 196\n",
      "Scraping Page no. 197\n",
      "Scraping Page no. 198\n",
      "Scraping Page no. 199\n",
      "Scraping Page no. 200\n",
      "Scraping Page no. 201\n",
      "Scraping Page no. 202\n",
      "Scraping Page no. 203\n",
      "Scraping Page no. 204\n",
      "Scraping Page no. 205\n",
      "Scraping Page no. 206\n",
      "Scraping Page no. 207\n",
      "Scraping Page no. 208\n",
      "Scraping Page no. 209\n",
      "Scraping Page no. 210\n",
      "Scraping Page no. 211\n",
      "Scraping Page no. 212\n",
      "Scraping Page no. 213\n",
      "Scraping Page no. 214\n",
      "Scraping Page no. 215\n",
      "Scraping Page no. 216\n",
      "Scraping Page no. 217\n",
      "Scraping Page no. 218\n",
      "Scraping Page no. 219\n",
      "Scraping Page no. 220\n",
      "Scraping Page no. 221\n",
      "Scraping Page no. 222\n",
      "Scraping Page no. 223\n",
      "Scraping Page no. 224\n",
      "Scraping Page no. 225\n",
      "Scraping Page no. 226\n",
      "Scraping Page no. 227\n",
      "Scraping Page no. 228\n",
      "Scraping Page no. 229\n",
      "Scraping Page no. 230\n",
      "Scraping Page no. 231\n",
      "Scraping Page no. 232\n",
      "Scraping Page no. 233\n",
      "Scraping Page no. 234\n",
      "Scraping Page no. 235\n",
      "Scraping Page no. 236\n",
      "Scraping Page no. 237\n",
      "Scraping Page no. 238\n",
      "Scraping Page no. 239\n",
      "Scraping Page no. 240\n",
      "Scraping Page no. 241\n",
      "Scraping Page no. 242\n",
      "Scraping Page no. 243\n",
      "Scraping Page no. 244\n",
      "Scraping Page no. 245\n",
      "Scraping Page no. 246\n",
      "Scraping Page no. 247\n",
      "Scraping Page no. 248\n",
      "Scraping Page no. 249\n",
      "Scraping Page no. 250\n",
      "Scraping Page no. 251\n",
      "Scraping Page no. 252\n",
      "Scraping Page no. 253\n",
      "Scraping Page no. 254\n",
      "Scraping Page no. 255\n",
      "Scraping Page no. 256\n",
      "Scraping Page no. 257\n",
      "Scraping Page no. 258\n",
      "Scraping Page no. 259\n",
      "Scraping Page no. 260\n",
      "Scraping Page no. 261\n",
      "Scraping Page no. 262\n",
      "Scraping Page no. 263\n",
      "Scraping Page no. 264\n",
      "Scraping Page no. 265\n",
      "     Revenues_$M  Profits_$M    Assets_$M Total Stockholder Equity_$M  \\\n",
      "0    $514,405.00   $6,670.00  $219,295.00                  $72,496.00   \n",
      "1    $414,649.90   $5,845.00  $329,186.30                 $105,181.50   \n",
      "2    $396,556.00  $23,352.00  $399,194.00                 $198,646.00   \n",
      "3    $392,976.60   $2,270.50  $601,899.90                 $291,198.60   \n",
      "4    $387,056.00   $8,174.80  $572,309.50                 $240,041.50   \n",
      "..           ...         ...          ...                         ...   \n",
      "261   $43,974.40      $616.9   $78,908.50                  $20,412.20   \n",
      "262   $43,858.10      $306.5   $53,958.10                  $17,505.40   \n",
      "263   $43,634.00   $1,230.00  $146,130.00                  $36,285.00   \n",
      "264   $43,599.20  $-4,122.00   $44,349.00                   $8,688.00   \n",
      "265   $43,582.40   $1,064.50   $30,897.60                   $8,170.20   \n",
      "\n",
      "                                 company  \n",
      "0                                Walmart  \n",
      "1                          Sinopec Group  \n",
      "2                      Royal Dutch Shell  \n",
      "3               China National Petroleum  \n",
      "4                             State Grid  \n",
      "..                                   ...  \n",
      "261  China United Network Communications  \n",
      "262   Shaanxi Yanchang Petroleum (Group)  \n",
      "263               Charter Communications  \n",
      "264                          Tata Motors  \n",
      "265                   ZF Friedrichshafen  \n",
      "\n",
      "[266 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "# For 1st part (~266)\n",
    "browser = webdriver.Chrome(r\"C:\\Users\\Jeeho\\AppData\\Local\\Programs\\Python\\Python36\\chromedriver.exe\")\n",
    "browser.get('https://fortune.com/global500/2019/walmart')\n",
    "\n",
    "#For the  1st part\n",
    "\n",
    "df1 = pd.DataFrame(columns=['Revenues_$M','Profits_$M', 'Assets_$M', 'Total Stockholder Equity_$M'])\n",
    "c1 = []\n",
    "\n",
    "for i in [x for x in range(266)]:       \n",
    "#    table = browser.find_element_by_css_selector('tbody')\n",
    "    table = browser.find_element_by_xpath('//*[@id=\"content\"]/div[5]/div[1]/table/tbody')    \n",
    "    if i > 266:\n",
    "        break\n",
    "\n",
    "\n",
    "    try:\n",
    "        print(\"Scraping Page no. \" + str(i))\n",
    "        i = i + 1\n",
    "#        values1 =[]\n",
    "    \n",
    "        for row in table.find_elements_by_css_selector('tr.dataTable__row--34F3j'):\n",
    "            vals=[]\n",
    "            vals.append(str(([cell.text for cell in row.find_elements_by_xpath('//*[@id=\"content\"]/div[5]/div[1]/table/tbody/tr[1]/td[2]')])).strip('[]').strip(\"''\"))   \n",
    "            vals.append(str(([cell.text for cell in row.find_elements_by_xpath('//*[@id=\"content\"]/div[5]/div[1]/table/tbody/tr[2]/td[2]')])).strip('[]').strip(\"''\"))   \n",
    "            vals.append(str(([cell.text for cell in row.find_elements_by_xpath('//*[@id=\"content\"]/div[5]/div[1]/table/tbody/tr[3]/td[2]')])).strip('[]').strip(\"''\"))   \n",
    "            vals.append(str(([cell.text for cell in row.find_elements_by_xpath('//*[@id=\"content\"]/div[5]/div[1]/table/tbody/tr[4]/td[2]')])).strip('[]').strip(\"''\"))   \n",
    "            \n",
    "#        values1.append(vals)\n",
    "        comp1 = str(([c.text for c in row.find_elements_by_xpath('//*[@id=\"content\"]/div[1]/div[1]/div/h1/span')])).strip('[]').strip(\"''\")    \n",
    "                                                                           \n",
    "        #values1.append(value1)                       \n",
    "        c1.append(comp1)\n",
    "        \n",
    "#        s1 = pd.Series(values1,index=df1.columns)\n",
    "        s1 = pd.Series(vals,index=df1.columns)\n",
    "\n",
    "        cs1 = pd.Series(c1) \n",
    "        df1 = df1.append(s1,ignore_index=True)\n",
    "        \n",
    "        try:\n",
    "\n",
    "            WebDriverWait(browser, 6).until(EC.element_to_be_clickable((By.CSS_SELECTOR, \"div.singlePagination__next2--3D89W\"))).click()\n",
    "            time.sleep(5)\n",
    "\n",
    "        except (socket.gaierror, requests.ConnectionError) as e:\n",
    "            if e.errno != 10054:\n",
    "                continue\n",
    "            reconnect()\n",
    "\n",
    "\n",
    "\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        break\n",
    "\n",
    "df1['company'] = cs1\n",
    "       \n",
    "print(df1)\n",
    "\n",
    "browser.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Revenues_$M  Profits_$M    Assets_$M Total Stockholder Equity_$M  \\\n",
      "0    $514,405.00   $6,670.00  $219,295.00                  $72,496.00   \n",
      "1    $414,649.90   $5,845.00  $329,186.30                 $105,181.50   \n",
      "2    $396,556.00  $23,352.00  $399,194.00                 $198,646.00   \n",
      "3    $392,976.60   $2,270.50  $601,899.90                 $291,198.60   \n",
      "4    $387,056.00   $8,174.80  $572,309.50                 $240,041.50   \n",
      "..           ...         ...          ...                         ...   \n",
      "261   $43,974.40      $616.9   $78,908.50                  $20,412.20   \n",
      "262   $43,858.10      $306.5   $53,958.10                  $17,505.40   \n",
      "263   $43,634.00   $1,230.00  $146,130.00                  $36,285.00   \n",
      "264   $43,599.20  $-4,122.00   $44,349.00                   $8,688.00   \n",
      "265   $43,582.40   $1,064.50   $30,897.60                   $8,170.20   \n",
      "\n",
      "                                 company  \n",
      "0                                Walmart  \n",
      "1                          Sinopec Group  \n",
      "2                      Royal Dutch Shell  \n",
      "3               China National Petroleum  \n",
      "4                             State Grid  \n",
      "..                                   ...  \n",
      "261  China United Network Communications  \n",
      "262   Shaanxi Yanchang Petroleum (Group)  \n",
      "263               Charter Communications  \n",
      "264                          Tata Motors  \n",
      "265                   ZF Friedrichshafen  \n",
      "\n",
      "[266 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.to_csv(r'C:\\Users\\Jeeho\\Documents\\Python Scripts\\Capstone project\\Web_Scrap\\Company_Valuation\\company_key_financials_p1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping Page no. 0\n",
      "Scraping Page no. 1\n",
      "Scraping Page no. 2\n",
      "Scraping Page no. 3\n",
      "Scraping Page no. 4\n",
      "Scraping Page no. 5\n",
      "Scraping Page no. 6\n",
      "Scraping Page no. 7\n",
      "Scraping Page no. 8\n",
      "Scraping Page no. 9\n",
      "Scraping Page no. 10\n",
      "Scraping Page no. 11\n",
      "Scraping Page no. 12\n",
      "Scraping Page no. 13\n",
      "Scraping Page no. 14\n",
      "Scraping Page no. 15\n",
      "Scraping Page no. 16\n",
      "Scraping Page no. 17\n",
      "Scraping Page no. 18\n",
      "Scraping Page no. 19\n",
      "Scraping Page no. 20\n",
      "Scraping Page no. 21\n",
      "Scraping Page no. 22\n",
      "Scraping Page no. 23\n",
      "Scraping Page no. 24\n",
      "Scraping Page no. 25\n",
      "Scraping Page no. 26\n",
      "Scraping Page no. 27\n",
      "Scraping Page no. 28\n",
      "Scraping Page no. 29\n",
      "Scraping Page no. 30\n",
      "Scraping Page no. 31\n",
      "Scraping Page no. 32\n",
      "Scraping Page no. 33\n",
      "Scraping Page no. 34\n",
      "Scraping Page no. 35\n",
      "Scraping Page no. 36\n",
      "Scraping Page no. 37\n",
      "Scraping Page no. 38\n",
      "Scraping Page no. 39\n",
      "Scraping Page no. 40\n",
      "Scraping Page no. 41\n",
      "Scraping Page no. 42\n",
      "Scraping Page no. 43\n",
      "Scraping Page no. 44\n",
      "Scraping Page no. 45\n",
      "Scraping Page no. 46\n",
      "Scraping Page no. 47\n",
      "Scraping Page no. 48\n",
      "Scraping Page no. 49\n",
      "Scraping Page no. 50\n",
      "Scraping Page no. 51\n",
      "Scraping Page no. 52\n",
      "Scraping Page no. 53\n",
      "Scraping Page no. 54\n",
      "Scraping Page no. 55\n",
      "Scraping Page no. 56\n",
      "Scraping Page no. 57\n",
      "Scraping Page no. 58\n",
      "Scraping Page no. 59\n",
      "Scraping Page no. 60\n",
      "Scraping Page no. 61\n",
      "Scraping Page no. 62\n",
      "Scraping Page no. 63\n",
      "Scraping Page no. 64\n",
      "Scraping Page no. 65\n",
      "Scraping Page no. 66\n",
      "Scraping Page no. 67\n",
      "Scraping Page no. 68\n",
      "Scraping Page no. 69\n",
      "Scraping Page no. 70\n",
      "Scraping Page no. 71\n",
      "Scraping Page no. 72\n",
      "Scraping Page no. 73\n",
      "Scraping Page no. 74\n",
      "Scraping Page no. 75\n",
      "Scraping Page no. 76\n",
      "Scraping Page no. 77\n",
      "Scraping Page no. 78\n",
      "Scraping Page no. 79\n",
      "Scraping Page no. 80\n",
      "Scraping Page no. 81\n",
      "Scraping Page no. 82\n",
      "Scraping Page no. 83\n",
      "Scraping Page no. 84\n",
      "Scraping Page no. 85\n",
      "Scraping Page no. 86\n",
      "Scraping Page no. 87\n",
      "Scraping Page no. 88\n",
      "Scraping Page no. 89\n",
      "Scraping Page no. 90\n",
      "Scraping Page no. 91\n",
      "Scraping Page no. 92\n",
      "Scraping Page no. 93\n",
      "Scraping Page no. 94\n",
      "Scraping Page no. 95\n",
      "Scraping Page no. 96\n",
      "Scraping Page no. 97\n",
      "Scraping Page no. 98\n",
      "Scraping Page no. 99\n",
      "Scraping Page no. 100\n",
      "Scraping Page no. 101\n",
      "Scraping Page no. 102\n",
      "Scraping Page no. 103\n",
      "Scraping Page no. 104\n",
      "Scraping Page no. 105\n",
      "Scraping Page no. 106\n",
      "Scraping Page no. 107\n",
      "Scraping Page no. 108\n",
      "Scraping Page no. 109\n",
      "Scraping Page no. 110\n",
      "Scraping Page no. 111\n",
      "Scraping Page no. 112\n",
      "Scraping Page no. 113\n",
      "Scraping Page no. 114\n",
      "Scraping Page no. 115\n",
      "Scraping Page no. 116\n",
      "Scraping Page no. 117\n",
      "Scraping Page no. 118\n",
      "Scraping Page no. 119\n",
      "Scraping Page no. 120\n",
      "Scraping Page no. 121\n",
      "Scraping Page no. 122\n",
      "Scraping Page no. 123\n",
      "Scraping Page no. 124\n",
      "Scraping Page no. 125\n",
      "Scraping Page no. 126\n",
      "Scraping Page no. 127\n",
      "Scraping Page no. 128\n",
      "Scraping Page no. 129\n",
      "Scraping Page no. 130\n",
      "Scraping Page no. 131\n",
      "Scraping Page no. 132\n",
      "Scraping Page no. 133\n",
      "Scraping Page no. 134\n",
      "Scraping Page no. 135\n",
      "Scraping Page no. 136\n",
      "Scraping Page no. 137\n",
      "Scraping Page no. 138\n",
      "Scraping Page no. 139\n",
      "Scraping Page no. 140\n",
      "Scraping Page no. 141\n",
      "Scraping Page no. 142\n",
      "Scraping Page no. 143\n",
      "Scraping Page no. 144\n",
      "Scraping Page no. 145\n",
      "Scraping Page no. 146\n",
      "Scraping Page no. 147\n",
      "Scraping Page no. 148\n",
      "Scraping Page no. 149\n",
      "Scraping Page no. 150\n",
      "Scraping Page no. 151\n",
      "Scraping Page no. 152\n",
      "Scraping Page no. 153\n",
      "Scraping Page no. 154\n",
      "Scraping Page no. 155\n",
      "Scraping Page no. 156\n",
      "Scraping Page no. 157\n",
      "Scraping Page no. 158\n",
      "Scraping Page no. 159\n",
      "Scraping Page no. 160\n",
      "Scraping Page no. 161\n",
      "Scraping Page no. 162\n",
      "Scraping Page no. 163\n",
      "Scraping Page no. 164\n",
      "Scraping Page no. 165\n",
      "Scraping Page no. 166\n",
      "Scraping Page no. 167\n",
      "Scraping Page no. 168\n",
      "Scraping Page no. 169\n",
      "Scraping Page no. 170\n",
      "Scraping Page no. 171\n",
      "Scraping Page no. 172\n",
      "Scraping Page no. 173\n",
      "Scraping Page no. 174\n",
      "Scraping Page no. 175\n",
      "Scraping Page no. 176\n",
      "Scraping Page no. 177\n",
      "Scraping Page no. 178\n",
      "Scraping Page no. 179\n",
      "Scraping Page no. 180\n",
      "Scraping Page no. 181\n",
      "Scraping Page no. 182\n",
      "Scraping Page no. 183\n",
      "Scraping Page no. 184\n",
      "Scraping Page no. 185\n",
      "Scraping Page no. 186\n",
      "Scraping Page no. 187\n",
      "Scraping Page no. 188\n",
      "Scraping Page no. 189\n",
      "Scraping Page no. 190\n",
      "Scraping Page no. 191\n",
      "Scraping Page no. 192\n",
      "Scraping Page no. 193\n",
      "Scraping Page no. 194\n",
      "Scraping Page no. 195\n",
      "Scraping Page no. 196\n",
      "Scraping Page no. 197\n",
      "Scraping Page no. 198\n",
      "Scraping Page no. 199\n",
      "Scraping Page no. 200\n",
      "Scraping Page no. 201\n",
      "Scraping Page no. 202\n",
      "Scraping Page no. 203\n",
      "Scraping Page no. 204\n",
      "Scraping Page no. 205\n",
      "Scraping Page no. 206\n",
      "Scraping Page no. 207\n",
      "Scraping Page no. 208\n",
      "Scraping Page no. 209\n",
      "Scraping Page no. 210\n",
      "Scraping Page no. 211\n",
      "Scraping Page no. 212\n",
      "Scraping Page no. 213\n",
      "Scraping Page no. 214\n",
      "Scraping Page no. 215\n",
      "Scraping Page no. 216\n",
      "Scraping Page no. 217\n",
      "Scraping Page no. 218\n",
      "Scraping Page no. 219\n",
      "Scraping Page no. 220\n",
      "Scraping Page no. 221\n",
      "Scraping Page no. 222\n",
      "Scraping Page no. 223\n",
      "Scraping Page no. 224\n",
      "Scraping Page no. 225\n",
      "Scraping Page no. 226\n",
      "Scraping Page no. 227\n",
      "Scraping Page no. 228\n",
      "Scraping Page no. 229\n",
      "Scraping Page no. 230\n",
      "Scraping Page no. 231\n",
      "Scraping Page no. 232\n",
      "Message: \n",
      "\n",
      "    Revenues_$M Profits_$M    Assets_$M Total Stockholder Equity_$M  \\\n",
      "0    $43,425.30       $880  $311,449.30                  $21,006.50   \n",
      "1    $43,332.90  $3,782.90  $360,361.10                  $26,292.90   \n",
      "2    $43,281.00  $6,921.00  $188,602.00                  $22,290.00   \n",
      "3    $43,270.00     $512.6  $214,141.90                  $14,478.10   \n",
      "4    $43,263.20  $1,079.90   $39,199.60                   $5,015.80   \n",
      "..          ...        ...          ...                         ...   \n",
      "228  $25,067.30  $2,360.80   $17,920.60                   $9,792.10   \n",
      "229  $25,002.70  $4,235.10  $589,481.40                  $34,823.70   \n",
      "230  $24,931.70  $1,794.60  $117,398.30                   $8,477.50   \n",
      "231  $24,816.00     $314.8    $7,870.20                   $2,438.00   \n",
      "232  $24,796.60  $2,494.20   $47,983.80                  $20,326.10   \n",
      "\n",
      "                     company  \n",
      "0    New York Life Insurance  \n",
      "1            Banco do Brasil  \n",
      "2           American Express  \n",
      "3                 Nationwide  \n",
      "4                        ACS  \n",
      "..                       ...  \n",
      "228                    Nucor  \n",
      "229         Bank of Montreal  \n",
      "230  Taikang Insurance Group  \n",
      "231        Ultrapar Holdings  \n",
      "232              Air Liquide  \n",
      "\n",
      "[233 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "# For 2nd part (268~)\n",
    "browser = webdriver.Chrome(r\"C:\\Users\\Jeeho\\AppData\\Local\\Programs\\Python\\Python36\\chromedriver.exe\")\n",
    "browser.get('https://fortune.com/global500/2019/new-york-life-insurance/')\n",
    "\n",
    "df2 = pd.DataFrame(columns=['Revenues_$M','Profits_$M', 'Assets_$M', 'Total Stockholder Equity_$M'])\n",
    "c2 = []\n",
    "\n",
    "for i in [x for x in range(233)]:       \n",
    "#    table = browser.find_element_by_css_selector('tbody')\n",
    "    table = browser.find_element_by_xpath('//*[@id=\"content\"]/div[5]/div[1]/table/tbody')    \n",
    "    if i > 233:\n",
    "        break\n",
    "\n",
    "\n",
    "    try:\n",
    "        print(\"Scraping Page no. \" + str(i))\n",
    "        i = i + 1\n",
    "    \n",
    "        for row in table.find_elements_by_css_selector('tr.dataTable__row--34F3j'):\n",
    "            vals2=[]\n",
    "            vals2.append(str(([cell.text for cell in row.find_elements_by_xpath('//*[@id=\"content\"]/div[5]/div[1]/table/tbody/tr[1]/td[2]')])).strip('[]').strip(\"''\"))   \n",
    "            vals2.append(str(([cell.text for cell in row.find_elements_by_xpath('//*[@id=\"content\"]/div[5]/div[1]/table/tbody/tr[2]/td[2]')])).strip('[]').strip(\"''\"))   \n",
    "            vals2.append(str(([cell.text for cell in row.find_elements_by_xpath('//*[@id=\"content\"]/div[5]/div[1]/table/tbody/tr[3]/td[2]')])).strip('[]').strip(\"''\"))   \n",
    "            vals2.append(str(([cell.text for cell in row.find_elements_by_xpath('//*[@id=\"content\"]/div[5]/div[1]/table/tbody/tr[4]/td[2]')])).strip('[]').strip(\"''\"))   \n",
    "            \n",
    "        comp2 = str(([c.text for c in row.find_elements_by_xpath('//*[@id=\"content\"]/div[1]/div[1]/div/h1/span')])).strip('[]').strip(\"''\")    \n",
    "                                                                           \n",
    "        c2.append(comp2)\n",
    "        \n",
    "        s2 = pd.Series(vals2,index=df2.columns)\n",
    "\n",
    "        cs2 = pd.Series(c2) \n",
    "        df2 = df2.append(s2,ignore_index=True)\n",
    "        \n",
    "        try:\n",
    "\n",
    "            WebDriverWait(browser, 6).until(EC.element_to_be_clickable((By.CSS_SELECTOR, \"div.singlePagination__next2--3D89W\"))).click()\n",
    "            time.sleep(5)\n",
    "\n",
    "        except (socket.gaierror, requests.ConnectionError) as e:\n",
    "            if e.errno != 10054:\n",
    "                continue\n",
    "            reconnect()\n",
    "\n",
    "\n",
    "\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        break\n",
    "\n",
    "df2['company'] = cs2\n",
    "       \n",
    "print(df2)\n",
    "\n",
    "browser.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.to_csv(r'C:\\Users\\Jeeho\\Documents\\Python Scripts\\Capstone project\\Web_Scrap\\Company_Valuation\\company_key_financials_p2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Revenues_$M  Profits_$M    Assets_$M Total Stockholder Equity_$M  \\\n",
      "0    $514,405.00   $6,670.00  $219,295.00                  $72,496.00   \n",
      "1    $414,649.90   $5,845.00  $329,186.30                 $105,181.50   \n",
      "2    $396,556.00  $23,352.00  $399,194.00                 $198,646.00   \n",
      "3    $392,976.60   $2,270.50  $601,899.90                 $291,198.60   \n",
      "4    $387,056.00   $8,174.80  $572,309.50                 $240,041.50   \n",
      "..           ...         ...          ...                         ...   \n",
      "494   $25,067.30   $2,360.80   $17,920.60                   $9,792.10   \n",
      "495   $25,002.70   $4,235.10  $589,481.40                  $34,823.70   \n",
      "496   $24,931.70   $1,794.60  $117,398.30                   $8,477.50   \n",
      "497   $24,816.00      $314.8    $7,870.20                   $2,438.00   \n",
      "498   $24,796.60   $2,494.20   $47,983.80                  $20,326.10   \n",
      "\n",
      "                      company  \n",
      "0                     Walmart  \n",
      "1               Sinopec Group  \n",
      "2           Royal Dutch Shell  \n",
      "3    China National Petroleum  \n",
      "4                  State Grid  \n",
      "..                        ...  \n",
      "494                     Nucor  \n",
      "495          Bank of Montreal  \n",
      "496   Taikang Insurance Group  \n",
      "497         Ultrapar Holdings  \n",
      "498               Air Liquide  \n",
      "\n",
      "[499 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "company_key_financials_all=df1.append(df2, ignore_index=True)\n",
    "print(company_key_financials_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "company_key_financials_all.to_csv(r'C:\\Users\\Jeeho\\Documents\\Python Scripts\\Capstone project\\Web_Scrap\\Company_Valuation\\company_key_financials_all.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
